import lief
import sys
import csv
import os
from subprocess import DEVNULL, PIPE, Popen
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import joblib
#from sklearn.naive_bayes import GaussianNB
#from sklearn.ensemble import RandomForestClassifier

# spracovanie suboru do premennej, ktora obsahuje mnoho informacii
def parse(filepath):
    try:
        parsed = lief.parse(filepath)
    except lief.exception as e:  # pri pripadnej chybe
        print(e)                 # ju vypiseme
        sys.exit(1)
    return parsed

# vypocet priemernej entropie suboru
def calculate_average_entropy(sections):
    totalEntropy = 0
    averageEntropy = 0  
    for section in sections: # zaznamenavame entropiu vsetkych
        totalEntropy += section.entropy # sekcii binarneho suboru
        averageEntropy += 1
    if averageEntropy == 0:
        return averageEntropy
    averageEntropy = round(totalEntropy / averageEntropy, 5)
    return averageEntropy

# staticka analyza suboru a zapisovanie vysledkov do vektora vlastnosti
def static_analysis(filepath):
    parsed_filepath = parse(filepath)
    if not parsed_filepath:
        return 2
    parsed_file = parsed_filepath.abstract
    # zistovanie formatu spustitelneho suboru
    if int(parsed_file.format) != 1: # ELF
        print("Unsupported type of executable")
        return 2             # 2 reprezentuje zlyhanie funkcie a vykresli sa adekvatna obrazovka
    feature_vector = list()
    header = parsed_file.header
    averageEntropy = calculate_average_entropy(parsed_file.sections)
    # zapisovanie do pola, ktore bude neskor pridane do databazy vysledkov
    feature_vector.append(len(parsed_file.libraries))           # Pocet importovanych kniznic
    feature_vector.append(len(parsed_file.imported_functions))  # Pocet importovanych funkcii
    feature_vector.append(len(parsed_file.exported_functions))  # Pocet exportovanych funkcii
    feature_vector.append(averageEntropy)                       # Priemerna entropia sekcii suboru
    # 1 = subor NEmoze spustit alokovane miesto; 0 = subor moze, cize NX bit off
    feature_vector.append(1) if parsed_file.has_nx else feature_vector.append(0) 
    # 1 = subor je pozicne nezavisly; 0 == subor je pozicne zavisly
    feature_vector.append(1) if parsed_file.is_pie else feature_vector.append(0) 
    # Endianita vyuzivana v subore
    if int(header.endianness) == 2:
        feature_vector.append(0)    # maly endian
    else:
        feature_vector.append(1)    # velky endian
    if len(feature_vector) != 7:
        print("Static analysis cant gather all data!")
        print(feature_vector)
        return 2            # 2 reprezentuje zlyhanie funkcie a vykresli sa adekvatna obrazovka
            
    return feature_vector

# metoda vyuzita na odstranenie koncovky '\n' z kaazdeho riadku
def removesuffix(self: str, suffix: str, /) -> str:
    # suffix='' should not call self[:-0].
    if suffix and self.endswith(suffix):
        return self[:-len(suffix)]
    else:
        return self[:]

# Spustenie skriptu, pockanie na vysledok a zapis dat do zoznamu
def dynamic_analysis(filepath):  
    script_path = '/home/dejko/virtualneMasiny/ubuntuMasina/run.sh'
    stream = Popen([script_path, filepath], stdout=PIPE, stderr=DEVNULL)
    detected_system_calls = list() # spustenie skriptu a presmerovanie jeho vystupu do pipe-i
    for line in stream.stdout:     # kazdy riadok vystupu pipe-i potrebujeme ulozit
        detected_system_calls.append(removesuffix(line.decode('ascii'), '\n'))
    return detected_system_calls


def dynamicke_spracovanie(detected_system_calls, feature_vector):
    # zoznam systemovych volani, ktore by mohli byt vyuzitelne pri odhade skodlivosti suboru
    calls_to_detect = list(['accept', 'access', 'add_key', 'bind', 'brk', 
                          'capset', 'chmod', 'chown', 'chroot', 'clone', 'connect', 'copy_file_range', 'creat',
                          'dup', 'eventfd', 'execve', 'execveat', 'fchmod', 'fchmodat', 'fchown', 'fchown32', 
                          'fcntl', 'flock', 'fork', 'fsync', 'get_thread_area', 'getcpu', 'init_module', 'ioctl', 
                          'iopl', 'kill', 'listen', 'lseek', 'mbind', 'migrate_pages', 'mkdir', 'mkdirat', 'mount',
                          'nice', 'open', 'openat', 'pause', 'pipe', 'preadv', 'pwritev', 'read', 'readdir', 
                          'readlink', 'readv', 'recv', 'recvfrom', 'recvmsg', 'request_key', 'rmdir', 
                          'rt_sigaction', 'rt_sigprocmask', 'ppoll', '', 'pipe2', 'munmap', 'getsocketname', 
                          'wait4', 'exit_group', 'pidfd_send_signal', 'prctl', 'mlock', 'mlock2', 
                          'sched_get_priority_max', 'sigsuspend', 'fallocate', 'pkey_alloc', 'setuid', 'poll', 
                          'futex', 'get_robust_list', 'rt_sigreturn', 'readahead', 'semctl', 'send', 'sendfile', 
                          'sendmsg', 'sendto', 'setpriority', 'setns', 'shmctl', 'sgetmask', 'signal', 'socket', 
                          'stat', 'statfs', 'sync', 'syncfs', 'sysinfo', 'tee', 'time', 'tkill', 'umask', 'uname', 
                          'unlink', 'ustat', 'utime', 'vfork', 'vmsplice', 'wait', 'waitpid', 'write', 'writev', 
                          'mmap', 'prlimit', 'setgid'])
    for wanted_call in calls_to_detect:
        if wanted_call in detected_system_calls:
            feature_vector.append(1) # hladane systemove volanie je pritomne vo vysledku analyzy
        else:
            feature_vector.append(0) # hladane systemove volanie NEBOLO detekovane
        
    
def store_results(feature_vector):
    filepath = '/home/dejko/results/all_analysis_results.csv'
    # zapis vysledkov do databazoveho suboru
    if os.path.exists(filepath): # iba zapis vysledkov
        with open(filepath, "a", encoding='UTF8') as file:
            pen = csv.writer(file)
            pen.writerow(feature_vector)
    else:
        with open(filepath, "w+", encoding='UTF8') as file: # vytvorenie suboru a zapis oznaceni + vysledkov
            pen = csv.writer(file)
            pen.writerow(['imported_libraries','imported_functions','exported_functions', 'entropy','NX_protection',
                          'position_independancy','endianness', 'accept', 'access', 'add_key', 'bind', 'brk', 
                          'capset', 'chmod', 'chown', 'chroot', 'clone', 'connect', 'copy_file_range', 'creat'
                          , 'dup', 'eventfd', 'execve', 'execveat', 'fchmod', 'fchmodat', 'fchown', 'fchown32', 
                          'fcntl', 'flock', 'fork', 'fsync', 'get_thread_area', 'getcpu', 'init_module', 'ioctl', 
                          'iopl', 'kill', 'listen', 'lseek', 'mbind', 'migrate_pages', 'mkdir', 'mkdirat', 'mount',
                          'nice', 'open', 'openat', 'pause', 'pipe', 'preadv', 'pwritev', 'read', 'readdir', 
                          'readlink', 'readv', 'recv', 'recvfrom', 'recvmsg', 'request_key', 'rmdir', 
                          'rt_sigaction', 'rt_sigprocmask', 'ppoll', '', 'pipe2', 'munmap', 'getsocketname', 
                          'wait4', 'exit_group', 'pidfd_send_signal', 'prctl', 'mlock', 'mlock2', 
                          'sched_get_priority_max', 'sigsuspend', 'fallocate', 'pkey_alloc', 'setuid', 'poll', 
                          'futex', 'get_robust_list', 'rt_sigreturn', 'readahead', 'semctl', 'send', 'sendfile', 
                          'sendmsg', 'sendto', 'setpriority', 'setns', 'shmctl', 'sgetmask', 'signal', 'socket', 
                          'stat', 'statfs', 'sync', 'syncfs', 'sysinfo', 'tee', 'time', 'tkill', 'umask', 'uname', 
                          'unlink', 'ustat', 'utime', 'vfork', 'vmsplice', 'wait', 'waitpid', 'write', 'writev', 
                          'mmap', 'prlimit', 'setgid'])
            pen.writerow(feature_vector)
        
        
# funkcia urcena na natrenovanie modelu       
def play_with_models():
    all_results = '/home/dejko/results/all_analysis_results.csv'
    analysis_data = pd.read_csv(all_results)
    # nacitaniae dat do premennych pre dalsiu pracu
    X = analysis_data.drop('malware', axis=1)
    y = analysis_data['malware']
    # rozdelenie dat na trenovacie a testovaice v pomere 1 ku 5
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    svc_classifier = SVC(kernel='linear')   # vytvorenie klasifikatora
    svc_classifier.fit(X_train, y_train)    # natrenovanie klasifikatora
    y_pred = svc_classifier.predict(X_test) # vysledky testoavnia
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    print("Pocet trenovacich vektorov: 280")
    print("Pocet testovacich vektorov: 70")
    print("Pocet vlastnosti jedneho vektoru: "+str(analysis_data.shape[1]))
    print()
    print("KLASIFIKACIA SVM:")
    print("Spravne vyhodnotenych: "+str(tp+tn))
    print("Falosne pozitiva: "+str(fp))
    print("Falosne negativa: "+str(fn))
    print("Uspesnost predikcie: "+str(round(round(accuracy_score(y_test, y_pred), 4)*100, 4)) + "%")
    print("F2 skore:  "+str(round(round(f1_score(y_test, y_pred), 4)*100, 4)) + "%")
    # ulozenie natrenovaneho modelu do suboru
    joblib.dump(svc_classifier, "svc_trained_model.pkl")
    
    
# nacitanie ulozeneho modelu a predikcia novo ziskaneho vektora
def predict(feature_vector):
    import numpy as np # vektor musi byt 2D pole, je potrebny reshape
    vector_to_predict = np.array(feature_vector).reshape(1, -1)
    svm_classifier = joblib.load("svc_trained_model.pkl")
    prediction = svm_classifier.predict(vector_to_predict)
    return prediction[0]
    
    #GNB_classifier = GaussianNB()
    #GNB_classifier.fit(X_train, y_train)
    #y_pred = GNB_classifier.predict(X_test) 
    #print()
    #print("KLASIFIKACIA Naives Bayes:")
    #tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    #print("Spravne vyhodnotenych: "+str(tp+tn))
    #print("Falosne pozitiva: "+str(fp))
    #print("Falosne negativa: "+str(fn))
    #print("Uspesnost predikcie: "+str(round(round(accuracy_score(y_test, y_pred), 4)*100, 4)) + "%")
    #print("F1 skore:  "+str(round(round(f1_score(y_test, y_pred), 4)*100, 4)) + "%")
    
    #forest_classifier = RandomForestClassifier(max_leaf_nodes = 10, random_state=0)
    #forest_classifier.fit(X_train, y_train)
    #y_pred = forest_classifier.predict(X_test)
    #print()
    #print("KLASIFIKACIA Random Forest:")
    #tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    #print("Spravne vyhodnotenych: "+str(tp+tn))
    #print("Falosne pozitiva: "+str(fp))
    #print("Falosne negativa: "+str(fn))
    #print("Uspesnost predikcie: "+str(round(round(accuracy_score(y_test, y_pred), 4)*100, 4)) + "%")
    #print("F1 skore:  "+str(round(round(f1_score(y_test, y_pred), 4)*100, 4)) + "%")


    
    
def main():
    #if len(sys.argv) != 2:
    #    print('bad arg count')
    #    sys.exit(1)
    #filepath = sys.argv[1];
    #print(filepath)
    #try:
    #    feature_vector = static_analysis(filepath)
    #except AttributeError:
    #    sys.exit(1)
    #if feature_vector == 2:
    #    print("Zlyhame pri statickej")
    #    sys.exit(1)
    #detected_system_calls = dynamic_analysis(filepath)
    #dynamicke_spracovanie(detected_system_calls, feature_vector)
    #store_results(feature_vector)
    #print(feature_vector)
    #play_with_models()
    #predict()
    print("This is meant for testing and providing resources.")

if __name__ == '__main__':
   main()